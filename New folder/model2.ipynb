{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "46111563-a55d-4451-926f-6a3ff9352ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\b\\w{1,2}\\b', '', text)  # Remove words with 2 or fewer characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "abf093a6-afd3-4e06-84c6-969674e71ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bullying_words</th>\n",
       "      <th>type_bully</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Insult</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Threat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mockery</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tease</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bullying_words  type_bully\n",
       "0           Hate           1\n",
       "1       Insult             1\n",
       "2      Threat              1\n",
       "3      Mockery             1\n",
       "4     Tease                1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('bullyings.csv')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3b3b0ce4-085d-4480-a00a-a8c49bc96857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to 'bullying_words' column\n",
    "df['bullying_words'] = df['bullying_words'].apply(preprocess_text)\n",
    "\n",
    "# Splitting data into features and target\n",
    "X = df['bullying_words']\n",
    "Y = df['type_bully']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "077355c5-3c21-4791-9da8-e5bf843ee670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating TF-IDF vectorizer\n",
    "vec = feature_extraction.text.TfidfVectorizer(ngram_range=(1, 2), analyzer='char')\n",
    "\n",
    "# Creating the pipeline with TF-IDF vectorizer and logistic regression\n",
    "model_pipe = pipeline.Pipeline([('vec', vec), ('clf', linear_model.LogisticRegression())])\n",
    "\n",
    "# Training the model\n",
    "model_pipe.fit(X_train, Y_train)\n",
    "\n",
    "# Predicting on test data\n",
    "predict_val = model_pipe.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0b9328ba-993c-45bf-bb29-b8f186726754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.00%\n",
      "Confusion Matrix:\n",
      "[[ 0  3]\n",
      " [ 0 12]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a text to predict if it's bullying or non-bullying:  hate you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class for \"hate you\": 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Calculating accuracy\n",
    "accuracy = metrics.accuracy_score(Y_test, predict_val) * 100\n",
    "print(f'Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = metrics.confusion_matrix(Y_test, predict_val)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# User Input and Prediction\n",
    "user_input = input(\"Enter a text to predict if it's bullying or non-bullying: \")\n",
    "user_input_preprocessed = preprocess_text(user_input)\n",
    "predicted_class = model_pipe.predict([user_input_preprocessed])\n",
    "print(f'Predicted class for \"{user_input}\": {predicted_class[0]}')\n",
    "\n",
    "# # Example prediction\n",
    "# example_text = \"You're a wonderful person inside and out\"\n",
    "# predicted_class = model_pipe.predict([example_text])\n",
    "# print(f'Predicted class for \"{example_text}\": {predicted_class[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c243a860-36d7-4c78-a612-45a724384093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id bullying_words type_bully\n",
      "0  1000           Hate      bully\n",
      "1  1001       Insult        bully\n",
      "2  1002      Threat         bully\n",
      "3  1003      Mockery        bully\n",
      "4  1004     Tease           bully\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn import pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn import feature_extraction\n",
    "from sklearn import metrics\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\b\\w{1,2}\\b', '', text)  # Remove words with 2 or fewer characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    return text.strip()\n",
    "\n",
    "# Load the CSV file or create a DataFrame with sample data\n",
    "# data = {'bullying_words': ['you suck', 'you are amazing', 'go away', 'kind person']}\n",
    "# df = pd.DataFrame(data)\n",
    "df = pd.read_csv('csv.csv')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "74d8ff98-efb7-4471-9767-a36454e7a9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       bullying_words  type_bully\n",
      "0                                                Hate           1\n",
      "1                                              Insult           1\n",
      "2                                              Threat           1\n",
      "3                                             Mockery           1\n",
      "4                                               Tease           1\n",
      "5                                            Disagree           0\n",
      "6                                              Debate           0\n",
      "7                                             Dislike           0\n",
      "8                                           Criticize           0\n",
      "9                                            Disagree           0\n",
      "10  You're so dumb, you can't even understand simp...           1\n",
      "11            Why are you even here? Nobody likes you           1\n",
      "12  You're such a loser, always trying to fit in b...           1\n",
      "13  Nobody cares about what you have to say. Just ...           1\n",
      "14          You're ugly and nobody will ever love you           1\n",
      "15  I can't believe how pathetic you are. Get a life!           1\n",
      "16  You're a waste of space. Why don't you just di...           1\n",
      "17  Everyone laughs at you behind your back becaus...           1\n",
      "18  You'll never amount to anything. Might as well...           1\n",
      "19  Nobody wants to be around you. You're better o...           1\n",
      "20  You're such a crybaby. Can't handle a little c...           1\n",
      "21  Why do you even bother trying? You'll never be...           1\n",
      "22  You're so weak. I can't believe you let things...           1\n",
      "23  You are a loser and always will be. Just accep...           1\n",
      "24  You're so boring. Nobody wants to hear what yo...           1\n",
      "25      You're such a try-hard. Just give up already.           1\n",
      "26  Why are you even alive? You contribute nothing...           1\n",
      "27  You're so fat and ugly. No wonder nobody likes...           1\n",
      "28  You're so worthless. I don't know why anyone w...           1\n",
      "29  You're such a failure. Just stop embarrassing ...           1\n",
      "30  You're a joke. Everyone laughs at how pathetic...           1\n",
      "31  Nobody cares about your feelings. You're just ...           1\n",
      "32  You're so annoying. Just go away and leave us ...           1\n",
      "33  You'll never succeed at anything. Might as wel...           1\n",
      "34  Why do you even bother trying? You'll never be...           1\n",
      "35  You're so weak. I can't believe you let things...           1\n",
      "36  You're such a disappointment. I expected bette...           0\n",
      "37  You're such a burden. Nobody wants to deal wit...           0\n",
      "38  You're so useless. Can't even do the simplest ...           0\n",
      "39  You're a waste of space. Nobody would miss you...           0\n",
      "40          You're doing great! Keep up the good work           0\n",
      "41           You're a wonderful person inside and out           0\n",
      "42    You always bring positivity to those around you           0\n",
      "43      You're making a difference in people's lives.           0\n",
      "44     You have a beautiful soul that shines brightly           0\n",
      "45  You're so talented and capable. Believe in you...           0\n",
      "46  You're a ray of sunshine on even the gloomiest...           0\n",
      "47  You're valuable and worthy of all the good thi...           0\n",
      "48  You inspire others with your kindness and comp...           0\n",
      "49       You're not alone. We're here to support you.           0\n",
      "50                                           love you           0\n",
      "51                                        We love you           0\n",
      "52                                         lathalatha           1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a modified dataset with the same length for both lists\n",
    "data = {\n",
    "    'bullying_words': [\n",
    "        'Hate', 'Insult', 'Threat', 'Mockery', 'Tease',\n",
    "        'Disagree', 'Debate', 'Dislike', 'Criticize', 'Disagree',\n",
    "        'You\\'re so dumb, you can\\'t even understand simple things',\n",
    "        'Why are you even here? Nobody likes you',\n",
    "        'You\\'re such a loser, always trying to fit in but never succeeding',\n",
    "        'Nobody cares about what you have to say. Just shut up already',\n",
    "        'You\\'re ugly and nobody will ever love you',\n",
    "        'I can\\'t believe how pathetic you are. Get a life!',\n",
    "        'You\\'re a waste of space. Why don\\'t you just disappear?',\n",
    "        'Everyone laughs at you behind your back because you\\'re a joke',\n",
    "        'You\\'ll never amount to anything. Might as well give up now',\n",
    "        'Nobody wants to be around you. You\\'re better off alone',\n",
    "        'You\\'re such a crybaby. Can\\'t handle a little criticism?',\n",
    "        'Why do you even bother trying? You\\'ll never be good enough.',\n",
    "        'You\\'re so weak. I can\\'t believe you let things get to you.',\n",
    "        'You are a loser and always will be. Just accept it',\n",
    "        'You\\'re so boring. Nobody wants to hear what you have to say',\n",
    "        'You\\'re such a try-hard. Just give up already.',\n",
    "        'Why are you even alive? You contribute nothing to this world.',\n",
    "        'You\\'re so fat and ugly. No wonder nobody likes you.',\n",
    "        'You\\'re so worthless. I don\\'t know why anyone would be friends with you.',\n",
    "        'You\\'re such a failure. Just stop embarrassing yourself',\n",
    "        'You\\'re a joke. Everyone laughs at how pathetic you are.',\n",
    "        'Nobody cares about your feelings. You\\'re just an inconvenience.',\n",
    "        'You\\'re so annoying. Just go away and leave us alone.',\n",
    "        'You\\'ll never succeed at anything. Might as well give up now.',\n",
    "        'Why do you even bother trying? You\\'ll never be good enough.',\n",
    "        'You\\'re so weak. I can\\'t believe you let things get to you.',\n",
    "        'You\\'re such a disappointment. I expected better from you.',\n",
    "        'You\\'re such a burden. Nobody wants to deal with your problems',\n",
    "        'You\\'re so useless. Can\\'t even do the simplest tasks right.',\n",
    "        'You\\'re a waste of space. Nobody would miss you if you were gone',\n",
    "        'You\\'re doing great! Keep up the good work',\n",
    "        'You\\'re a wonderful person inside and out',\n",
    "        'You always bring positivity to those around you',\n",
    "        'You\\'re making a difference in people\\'s lives.',\n",
    "        'You have a beautiful soul that shines brightly',\n",
    "        'You\\'re so talented and capable. Believe in yourself!',\n",
    "        'You\\'re a ray of sunshine on even the gloomiest days',\n",
    "        'You\\'re valuable and worthy of all the good things in life.',\n",
    "        'You inspire others with your kindness and compassion.',\n",
    "        'You\\'re not alone. We\\'re here to support you.','love you', 'We love you', 'lathalatha'\n",
    "    ],\n",
    "    'type_bully': [\n",
    "        1, 1, 1, 1, 1,\n",
    "        0, 0, 0, 0, 0,\n",
    "        1, 1, 1, 1, 1,\n",
    "        1, 1, 1, 1, 1,\n",
    "        1, 1, 1, 1, 1,\n",
    "        1, 1, 1, 1, 1,\n",
    "        1, 1, 1, 1, 1,\n",
    "        1, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0,\n",
    "        0, 0, 1\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the modified dataset\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "942413c2-b1d7-4d51-96c8-4b5e625cc509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vec&#x27;, TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 2))),\n",
       "                (&#x27;clf&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vec&#x27;, TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 2))),\n",
       "                (&#x27;clf&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vec', TfidfVectorizer(analyzer='char', ngram_range=(1, 2))),\n",
       "                ('clf', LogisticRegression())])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing to 'bullying_words' column\n",
    "df['bullying_words'] = df['bullying_words'].apply(preprocess_text)\n",
    "\n",
    "# Splitting data into features and target\n",
    "# X = df['bullying_words']\n",
    "# Y = [1, 1, 1, 1, 1,\n",
    "#         0, 0, 0, 0, 0,\n",
    "#         1, 1, 1, 1, 1,\n",
    "#         1, 1, 1, 1, 1,\n",
    "#         1, 1, 1, 1, 1,\n",
    "#         1, 1, 1, 1, 1,\n",
    "#         1, 1, 1, 1, 1,\n",
    "#         1, 0, 0, 0, 0,\n",
    "#         0, 0, 0, 0, 0,\n",
    "#         0, 0, 0, 0, 0]  # Sample target data (1 for bullying, 0 for non-bullying)\n",
    "\n",
    "X = df['bullying_words']\n",
    "Y = df['type_bully']\n",
    "# Creating TF-IDF vectorizer\n",
    "vec = feature_extraction.text.TfidfVectorizer(ngram_range=(1, 2), analyzer='char')\n",
    "\n",
    "# Creating the pipeline with TF-IDF vectorizer and logistic regression\n",
    "model_pipe = pipeline.Pipeline([('vec', vec), ('clf', linear_model.LogisticRegression())])\n",
    "\n",
    "# Training the model\n",
    "model_pipe.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "69f0c0c6-d135-444e-81ae-84db55c045cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a text to predict if it's bullying or non-bullying:  dfgh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text \"dfgh\" is classified as bullying.\n"
     ]
    }
   ],
   "source": [
    "# User Input and Prediction\n",
    "user_input = input(\"Enter a text to predict if it's bullying or non-bullying: \")\n",
    "user_input_preprocessed = preprocess_text(user_input)\n",
    "predicted_class = model_pipe.predict([user_input_preprocessed])\n",
    "\n",
    "# Display predicted class to the user\n",
    "if predicted_class[0] == 1:\n",
    "    print(f'The text \"{user_input}\" is classified as bullying.')\n",
    "else:\n",
    "    print(f'The text \"{user_input}\" is classified as non-bullying.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b1f1a4f2-8401-49ad-9153-1ca31acbb1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import pickle\n",
    "new_file = open('model.pkl','wb')\n",
    "pickle.dump(model_pipe, new_file)\n",
    "new_file.close()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "53f915e4-8c30-460a-ba3b-544bba8ca725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'bulliesModel.ipynb',\n",
       " 'bullying.csv',\n",
       " 'bullyings.csv',\n",
       " 'content',\n",
       " 'content.zip',\n",
       " 'csv.csv',\n",
       " 'cyberbullying_tweets.csv',\n",
       " 'desktop.ini',\n",
       " 'GBM.ipynb',\n",
       " 'int',\n",
       " 'Interface',\n",
       " 'Lejone - Chrome.lnk',\n",
       " 'LOGIN',\n",
       " 'main.py',\n",
       " 'Microsoft Edge.lnk',\n",
       " 'model.pkl',\n",
       " 'model2.ipynb',\n",
       " 'model2.pkl',\n",
       " 'mongodb connection (4)',\n",
       " 'mongodb connection (4).zip',\n",
       " 'myapp.py',\n",
       " 'mycsv.csv',\n",
       " 'New Folder.zip',\n",
       " 'preparation.pptx',\n",
       " 'res.zip',\n",
       " 'response.zip',\n",
       " 'RF.ipynb',\n",
       " 'SVM.ipynb',\n",
       " 'Untitled.ipynb',\n",
       " 'Untitled1.ipynb',\n",
       " 'Visual Studio Code.lnk',\n",
       " 'WPS Office.lnk',\n",
       " 'WPS PDF.lnk']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce23fb6-9266-4a8d-b27f-cc21ed2150ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
