{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cddc389-c922-47a0-815c-1473cb07ca6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bullying_words</th>\n",
       "      <th>type_bully</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hate</td>\n",
       "      <td>bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Insult</td>\n",
       "      <td>bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Threat</td>\n",
       "      <td>bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mockery</td>\n",
       "      <td>bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Tease</td>\n",
       "      <td>bully</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id bullying_words type_bully\n",
       "0   1           Hate      bully\n",
       "1   2       Insult        bully\n",
       "2   3      Threat         bully\n",
       "3   4      Mockery        bully\n",
       "4   5     Tease           bully"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"load.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8014a54-808d-4a14-882a-9881bcbb5fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bullying_words</th>\n",
       "      <th>type_bully</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>464</td>\n",
       "      <td>r u gnon-bullynon-bullyd at art</td>\n",
       "      <td>non-bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>465</td>\n",
       "      <td>What&amp;;s your worst habit?</td>\n",
       "      <td>non-bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>466</td>\n",
       "      <td>hahahaha thanks i think? did you call me bea...</td>\n",
       "      <td>non-bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>467</td>\n",
       "      <td>summer :]</td>\n",
       "      <td>non-bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>468</td>\n",
       "      <td>Bugs Bunny or Mickey Mouse?</td>\n",
       "      <td>non-bully</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                     bullying_words type_bully\n",
       "463  464                    r u gnon-bullynon-bullyd at art  non-bully\n",
       "464  465                          What&;s your worst habit?  non-bully\n",
       "465  466    hahahaha thanks i think? did you call me bea...  non-bully\n",
       "466  467                                          summer :]  non-bully\n",
       "467  468                        Bugs Bunny or Mickey Mouse?  non-bully"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50a23e36-53d1-4378-83ce-d4b8ae96dec5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_balanced' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m  \n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Apply the preprocess function to create a new column 'processed_text'\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m df_balanced[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_balanced[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbullying_words\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(preprocess)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_balanced' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the spaCy English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Define the preprocess function to handle NaN values\n",
    "def preprocess(bullying_words):\n",
    "    if pd.notnull(bullying_words):  \n",
    "        doc = nlp(bullying_words)\n",
    "        filtered_tokens = []\n",
    "        for token in doc:\n",
    "            if not token.is_stop and not token.is_punct and not token.like_num:\n",
    "                filtered_tokens.append(token.lemma_)\n",
    "        return ' '.join(filtered_tokens)\n",
    "    else:\n",
    "        return ''  \n",
    "\n",
    "# Apply the preprocess function to create a new column 'processed_text'\n",
    "df_balanced['processed_text'] = df_balanced['bullying_words'].apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25d98b5b-c665-43f8-9543-6bd989d5905a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_balanced' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_balanced\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_balanced' is not defined"
     ]
    }
   ],
   "source": [
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "713452b6-f180-47c8-b881-f36800fc1048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under sampling taking random sample\n",
    "min_sample = 50\n",
    "df_bully = df[df.type_bully == \"bully\"].sample(min_sample, random_state=40)\n",
    "df_non_bully = df[df.type_bully == \"non-bully\"].sample(min_sample, random_state=40)\n",
    "\n",
    "# Combine the balanced dataframes\n",
    "df_balanced = pd.concat([df_bully, df_non_bully], axis=0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    df_balanced.bullying_words,\n",
    "    df_balanced.type_bully,\n",
    "    test_size=0.2,\n",
    "    random_state=40,\n",
    "    stratify=df_balanced.type_bully\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9173ce37-688b-40d5-8bfd-c27daf5274b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74     You're nothing but a waste of space. Nobody ne...\n",
       "364                          i never said i liked pryce.\n",
       "295                                         pelo e thata\n",
       "80     You're so pathetic. No wonder nobody respects ...\n",
       "34     Why do you even bother trying? You'll never be...\n",
       "                             ...                        \n",
       "403                          followed! follow me also :)\n",
       "301                                               flinty\n",
       "40             You're doing great! Keep up the good work\n",
       "272                                   kelello e le 'ngoe\n",
       "324                          I knw!!!!!  I hate that! D:\n",
       "Name: bullying_words, Length: 80, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd2601d5-d34e-4e47-9f67-cfea9e74cd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74         bully\n",
       "364    non-bully\n",
       "295        bully\n",
       "80         bully\n",
       "34         bully\n",
       "         ...    \n",
       "403    non-bully\n",
       "301        bully\n",
       "40     non-bully\n",
       "272        bully\n",
       "324        bully\n",
       "Name: type_bully, Length: 80, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "942b3a90-b125-4fc4-be1e-d90ad4b81142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bully       0.83      1.00      0.91        10\n",
      "   non-bully       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with TfidfVectorizer and LogisticRegression\n",
    "lejone_tfidf = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "lejone_tfidf.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "Y_pred_tfidf = lejone_tfidf.predict(X_test)\n",
    "\n",
    "# Evaluate the TF-IDF based model\n",
    "print(classification_report(Y_test, Y_pred_tfidf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "714d0131-4475-4cbe-9206-ce411349e2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bully       0.83      1.00      0.91        10\n",
      "   non-bully       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the testing data\n",
    "Y_pred = lejone_tfidf.predict(X_test)\n",
    "# Evaluate the model producing a classification report\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(Y_test, Y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0088f39-105a-431a-80ee-e2ddda739b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kha90.joblib']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "# Save the model to a file\n",
    "dump(lejone_tfidf, 'kha90.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96ef050-7c5b-4e12-a4f3-7fa798880feb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
